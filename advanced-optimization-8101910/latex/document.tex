\documentclass[12pt]{article}

\usepackage{geometry}
\geometry{a4paper,margin=2.5cm}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{enumitem}


\usepackage{xepersian}
\settextfont{XB Niloofar}
\setlatintextfont{Latin Modern Roman}
\defpersianfont\nastaliq[Scale=1.2]{IranNastaliq}

\setlength{\parskip}{0.6em}
\setlength{\parindent}{0pt}




\setlength{\parskip}{0.6em}
\setlength{\parindent}{0pt}

\title{یادداشت‌های درس بهینه‌سازی پیشرفته}
\author{بر اساس اسلایدهای درس بهینه‌سازی پیشرفته دانشگاه تهران}
\date{}


\begin{document}
\maketitle
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{جلسه اول: مقدمه‌ای بر بهینه‌سازی}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{اطلاعات کلی درس}

\begin{itemize}
	\item بارم‌بندی:
	\begin{itemize}
		\item تمرینات: ۳۰٪
		\item کویز: ۱۰٪
		\item میان‌ترم: ۳۰٪
		\item پایان‌ترم: ۳۰٪
		\item پروژه: ۱۰٪
	\end{itemize}
	\item ایمیل مدرس: \lr{reshad.hossini@ut.ac.ir}
	\item زمان مراجعه: با تعیین وقت قبلی، اتاق ۴۰۸ ساختمان قدیم.
	\item امتحان میان‌ترم: یکشنبه ۲۵ آبان.
\end{itemize}

\subsection{منابع درس}

\begin{itemize}
	\item مراجع اصلی:
	\begin{itemize}
		\item \lr{Numerical Optimization} نوشته‌ی \lr{Nocedal, Wright}
		\item \lr{Nonlinear Programming} نوشته‌ی \lr{Bertsekas}
		\item \lr{Convex Optimization} نوشته‌ی \lr{Boyd, Vandenberghe}
	\end{itemize}
	\item مباحث پیشرفته خارج از سرفصل اصلی:
	\begin{itemize}
		\item \lr{Fixed Point Theory and Applications} نوشته‌ی \lr{Agarwal, Meehan, O’Regan}
		\item \lr{Optimization Algorithms on Matrix Manifolds} نوشته‌ی \lr{Absil, Mahoney, Sepulchre}
		\item \lr{Optimization for Machine Learning} نوشته‌ی \lr{Sra, Nowozin, Wright}
		\item \lr{Dynamic Programming and Optimal Control} نوشته‌ی \lr{Bertsekas}
	\end{itemize}
	\item پیش‌نیازهای ریاضی:
	\begin{itemize}
		\item حساب چندمتغیره
		\item جبر ماتریسی
	\end{itemize}
\end{itemize}

% یادداشت تکمیلی:
% برای مرور سریع مفاهیم بهینه‌سازی محدب (مجموعه و تابع محدب، برنامه‌ریزی خطی و غیرخطی، KKT و ...) می‌توانید به کتاب Convex Optimization اثر Boyd و Vandenberghe و نیز درس‌نامه‌های آنلاین دانشگاه استنفورد درباره convex optimization مراجعه کنید.

\subsection{اهداف درس}

در این درس انتظار می‌رود دانشجو:

\begin{itemize}
	\item با روش‌های مختلف بهینه‌سازی آشنا شود و با توجه به نقاط قوت و ضعف هر روش، آن‌ها را در مسائل مناسب به‌درستی به‌کار ببرد.
	\item \textbf{قابل حل بودن مسائل} را تشخیص دهد؛ بسیاری از پیشرفت‌های جدید در علوم مرتبط با بهینه‌سازی با \emph{تغییر فرمول‌بندی مسأله} به یک مسأله‌ی قابل حل به‌دست آمده‌اند (مثال مهم: شبکه‌های عصبی عمیق).
	\item با تکیه بر پایه و دید ریاضی حاصل از این درس بتواند روش‌های موجود را برای کاربرد مورد نظر خود تغییر و سازگار کند.
\end{itemize}

\subsection{اهمیت بهینه‌سازی و مثال‌های کاربردی}

\begin{itemize}
	\item در اقتصاد: سرمایه‌گذاران باید در جایی سرمایه‌گذاری کنند که ریسک کم و سود بالا داشته باشد.
	\item در صنعت: سازندگان باید بازده بیشینه را در عملیات ساخت داشته باشند.
	\item در مهندسی: مهندسان پارامترهای طرح خود را برای کارایی بیشتر بهینه می‌کنند.
\end{itemize}

برخی از مسائلی که نیاز به بهینه‌سازی دارند:

\begin{itemize}
	\item تخمین پارامترهای شبکه‌های عصبی عمیق.
	\item کلاس‌بندی داده‌ها با استفاده از \lr{Support Vector Machine (SVM)}.
	\item خوشه‌بندی داده‌ها با استفاده از مدل‌های مخلوط.
	\item تقطیع تصویر با استفاده از کانتورهای فعال.
	\item تخمین ماتریس دوربین.
	\item به‌دست آوردن پارامترهای تنک در ابعاد بالا \lr{(Sparse recovery)}.
	\item کنترل و تصمیم‌گیری بهینه.
\end{itemize}

\subsection{واژه‌های کلیدی در بهینه‌سازی}

\begin{itemize}
	\item \textbf{تابع هدف} \lr{(Objective function)}: معیاری عددی که کارایی سیستم را مشخص می‌کند؛ مثل:
	\begin{itemize}
		\item بیشینه‌سازی سود سرمایه‌گذاری؛
		\item کمینه‌سازی خطای کلاس‌بندی؛
		\item کمینه‌سازی انرژی یا هزینه.
	\end{itemize}
	\item \textbf{پارامترها} (متغیرهای تصمیم): کمیت‌هایی که معرف سیستم هستند و باید طوری انتخاب شوند که تابع هدف بهینه شود.
	\item \textbf{قیود} \lr{(Constraints)}: محدودیت‌هایی بر روی متغیرها که در بسیاری از کاربردها وجود دارد.
\end{itemize}

\paragraph{مثال: دکانولوشن تصویر}

\[
y = x * w + \eta
\]

\begin{itemize}
	\item تابع هدف: کمینه‌کردن
	\[
	\|x * w - y\|.
	\]
	\item پارامترها: تصویر $x$ و فیلتر کانولوشن $w$.
	\item قیود:
	\[
	y > 0,\quad x > 0,\quad \sum_i w_i = 1.
	\]
\end{itemize}

\subsection{مدل‌سازی و فرمول‌بندی ریاضی}

\begin{itemize}
	\item \textbf{مدل‌سازی}: فرآیند تشخیص تابع هدف، متغیرها و قیود در یک مسأله‌ی واقعی.
	\item \textbf{شرایط بهینگی}: شرایطی برای بررسی بهینه بودن پارامترهای حاصل شده.
\end{itemize}

فرمول‌بندی کلی یک مسأله‌ی بهینه‌سازی:

\[
\begin{aligned}
	\min_{x \in \mathbb{R}^n} \quad & f(x) \\
	\text{s.t.} \quad & c_i(x) = 0,\quad i \in E,\\
	& c_i(x) \ge 0,\quad i \in I,
\end{aligned}
\]

که در آن:

\begin{itemize}
	\item $f$ تابع هدف است؛
	\item $x$ متغیرهای تصمیم هستند؛
	\item $E$ مجموعه‌ی قیود تساوی و $I$ مجموعه‌ی قیود نامساوی است.
\end{itemize}

\subsection{یک مثال دوبعدی با قیود}

\[
\begin{aligned}
	\min_{x_1,x_2\in\mathbb{R}} \quad & (x_1 - 2)^2 + (x_2 - 1)^2 \\
	\text{s.t.} \quad & x_1^2 - x_2 \le 0,\\
	& x_1 + x_2 \le 2.
\end{aligned}
\]

ناحیه‌ی قابل دسترس \lr{(Feasible region)}، ناحیه‌ای است که همه‌ی قیود در آن برقرارند. نقطه‌ی بهینه جایی است در این ناحیه که تابع هدف کمینه می‌شود.

\subsection{انواع اصلی مسائل بهینه‌سازی}

\subsubsection{پیوسته و گسسته}

\begin{itemize}
	\item در برخی کاربردها متغیرها فقط مقادیر صحیح (طبیعی) می‌پذیرند:
	\begin{itemize}
		\item تعداد نیروگاه‌هایی که در چند سال آینده باید ساخته شوند.
		\item تصمیم‌های دودویی مانند این‌که آیا کارخانه‌ای در یک شهر خاص ساخته شود یا نه.
	\end{itemize}
	\item در این حالت متغیرها در $\mathbb{N}$ یا زیرمجموعه‌ای از آن تعریف می‌شوند و مسأله \textbf{بهینه‌سازی گسسته} است.
	\item برای مسائل پیوسته، رفتار تابع هدف در همسایگی یک نقطه معمولاً «نرم‌تر» است و از ابزارهای حساب دیفرانسیل راحت‌تر می‌توان استفاده کرد.
	\item در بعضی مسائل گسسته، الگوریتم‌هایی مثل برنامه‌ریزی پویا (\lr{Dynamic Programming}) وجود دارد که مسأله را در زمان معقول حل می‌کنند.
\end{itemize}

\subsubsection{مقید و نامقید؛ خطی و غیرخطی}

\begin{itemize}
	\item \textbf{برنامه‌ریزی خطی} (LP): اگر تابع هدف و همه‌ی قیود \emph{خطی} در متغیرها باشند.
	\item \textbf{برنامه‌ریزی غیرخطی} (NLP): اگر حداقل یکی از تابع هدف یا قیود \emph{غیرخطی} باشد.
	\item \textbf{مسائل محلی و سراسری}:
	\begin{itemize}
		\item در بسیاری از مسائل غیرخطی، الگوریتم‌ها معمولاً فقط یک \textbf{کمینه‌ی محلی} می‌یابند.
		\item در مسائل محدب، هر کمینه‌ی محلی، کمینه‌ی سراسری هم هست؛ این ویژگی علت اصلی جذابیت بهینه‌سازی محدب است.:\lr{contentReference[oaicite:1]{index=1}}
	\end{itemize}
\end{itemize}

\subsection{مجموعه‌ها و توابع محدب}

\subsubsection{تعریف مجموعه محدب}

مجموعه‌ی $S$ محدب است اگر برای هر دو نقطه‌ی $x,y\in S$ و هر $\alpha \in [0,1]$، نقطه‌ی $\alpha x + (1-\alpha)y$ نیز در $S$ باشد:

\[
\forall x,y\in S,\ \forall \alpha\in[0,1] \quad \Rightarrow \quad \alpha x + (1-\alpha)y \in S.
\]

\subsubsection{تعریف تابع محدب}

تابع $f$ روی مجموعه‌ی محدب $S$، \textbf{محدب} است اگر برای هر $x,y\in S$ و $\alpha\in[0,1]$ داشته باشیم:

\[
f(\alpha x + (1-\alpha)y) \le \alpha f(x) + (1-\alpha)f(y).
\]

% یادداشت تکمیلی:
% به زبان هندسی: نمودار تابع محدب همیشه زیر (یا روی) طنابی قرار می‌گیرد که دو نقطه از نمودار را به هم وصل می‌کند. این خاصیت باعث می‌شود هر نقطه‌ای که گرادیان صفر دارد، بهینه‌ی سراسری باشد.

\subsubsection{نمونه‌هایی از مجموعه‌های محدب}

\begin{itemize}
	\item کره‌ی واحد:
	\[
	\{y\in\mathbb{R}^n \mid \|y\|_2 \le 1\}.
	\]
	\item چندوجهی‌ها (Polyhedra):
	\[
	\{x\in\mathbb{R}^n \mid Ax = b,\ Cx \le d\}.
	\]
\end{itemize}

\subsubsection{نمونه‌هایی از توابع محدب}

\begin{itemize}
	\item تابع خطی:
	\[
	f(x) = c^T x + \alpha.
	\]
	\item تابع درجه‌دوم با ماتریس هسیان معین‌مثبت:
	\[
	f(x) = x^T H x, \quad H \succ 0.
	\]
\end{itemize}

\subsection{برنامه‌ریزی محدب}

یک مسأله‌ی بهینه‌سازی \textbf{محدب} است اگر:

\begin{itemize}
	\item تابع هدف محدب باشد؛
	\item قیود نامساوی از نوع:
	\[
	g_i(x) \le 0
	\]
	باشند که هر $g_i$ تابعی \emph{مقعر} است (تا مجموعه‌ی قابل دسترس محدب گردد)؛
	\item قیود تساوی خطی باشند:
	\[
	A x = b.
	\]
\end{itemize}

در این صورت هر نقطه‌ی ایستا (که شرایط KKT را برآورده می‌کند) کمینه‌ی سراسری خواهد بود.

\subsection{بهینه‌سازی قطعی و تصادفی}

\begin{itemize}
	\item \textbf{بهینه‌سازی قطعی}: پارامترها و مدل کاملاً مشخص‌اند.
	\item \textbf{بهینه‌سازی تصادفی / مقاوم}:
	\begin{itemize}
		\item در برخی مسائل، مدل شامل پارامترهای تصادفی است (مثلاً تقاضای آینده، قیمت‌ها و ...).
		\item در بهینه‌سازی تصادفی، معمولاً تابع هدف امید ریاضی بازده یا هزینه است.
		\item در \textbf{بهینه‌سازی مقید-شانس} \lr{(Chance-constrained)}، قیود باید با احتمال بالایی برقرار باشند.
		\item در \textbf{بهینه‌سازی مقاوم} \lr{(Robust optimization)}، جواب باید برای تمام حالت‌های ممکن عدم‌قطعیت قابل قبول باشد.
	\end{itemize}
\end{itemize}

\subsection{چند کاربرد تصویری (طبق اسلایدها)}

(در این قسمت‌ها اسلایدها شامل تصاویر هستند؛ در فایل اصلی می‌توان تصاویر را با
 \verb|\includegraphics| 
 وارد کرد.)

\begin{itemize}
	\item کلاس‌بندی با \lr{SVM}: جدا کردن دو کلاس داده با یک هایپرپلین با مارجین بیشینه.
	\item برازش داده با شبکه‌های عصبی چندلایه.
	\item تخمین چگالی احتمال، تخمین سری زمانی، کنترل ربات، دید ماشین، تشخیص صدا، موتورهای جستجو، تشخیص بیماری، \lr{BCI}، شبکه‌های هوشمند برق، اتصال تصاویر\lr{ (Image stitching)}، ساختار از حرکت، مطالعات علوم اعصاب و ...
\end{itemize}

% یادداشت تکمیلی:
% تقریباً در تمام این کاربردها، مسأله اصلی به صورت "کمینه‌سازی یک تابع هزینه" فرمول‌بندی می‌شود؛ مثل مجموع مربعات خطا، منفی‌لاگ‌احتمال، یا توابع زیان (loss functions) در یادگیری ماشین.

\subsection{سرفصل (تا امتحان میان‌ترم)}

\begin{itemize}
	\item هفته اول و دوم: پایه‌های بهینه‌سازی و مثال‌ها (بهینه‌سازی محدب، برنامه‌ریزی خطی، الگوریتم‌های فراابتکاری).
	\item هفته سوم: پایه‌های بهینه‌سازی نامقید (فصل ۲ از مرجع اول و فصل ۱–۱ از مرجع دوم).
	\item هفته چهارم: روش‌های جستجوی خط (فصل ۳ از مرجع اول و فصول ۱–۲، ۱–۳، ۱–۴ از مرجع دوم).
	\item هفته پنجم: روش‌های ناحیه‌ی قابل اعتماد (فصل ۴ از مرجع اول).
	\item هفته ششم: روش گرادیان مزدوج و شبه‌نیوتن (فصول ۵،۶،۷ از مرجع اول و فصول ۱–۶، ۱–۷ از مرجع دوم).
	\item هفته هفتم: روش حداقل مربعات غیرخطی (فصل ۱۰ از مرجع اول و فصل ۱–۵ از مرجع دوم).
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{جلسه دوم: بهینه‌سازی تک‌متغیره و تعمیم مشتق}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{تعمیم مشتق به بعدهای بالاتر}

در حالت یک‌بعدی، بسط تیلور درجه اول در نقطه‌ی $x_0$:

\[
f(x_0 + y) = f(x_0) + f'(x_0) y + o(\|y\|).
\]

تابع در صورتی در نقطه‌ی $x_0$ مشتق‌پذیر است که این تقریب خطی برقرار باشد:

\[
\lim_{y\to 0} \frac{f(x_0 + y) - f(x_0) - f'(x_0) y}{\|y\|} = 0.
\]

در ابعاد بالاتر، به‌جای خطِ مماس، صفحه‌ی مماس (تخت‌خطی) را در نظر می‌گیریم. شرط مشتق‌پذیری در نقطه‌ی $x_0$:

\[
\lim_{y\to 0} \frac{f(x_0 + y) - f(x_0) - g^T y}{\|y\|} = 0,
\]

که در آن $g$ گرادیان تابع در $x_0$ است.

\subsection{گرادیان و مشتق جهت‌دار}

\begin{itemize}
	\item اگر در نقطه‌ای مشتق وجود داشته باشد، بردار $g$ \textbf{گرادیان} تابع خوانده می‌شود:
	\[
	\nabla f(x) =
	\begin{bmatrix}
		\dfrac{\partial f}{\partial x_1}\\[0.3em]
		\dfrac{\partial f}{\partial x_2}\\
		\vdots\\
		\dfrac{\partial f}{\partial x_n}
	\end{bmatrix}.
	\]
	\item \textbf{مشتق جهت‌دار} تابع در راستای $h$ در نقطه‌ی $x$:
	\[
	Df(x)\cdot h = \lim_{\varepsilon\to 0} \frac{f(x + \varepsilon h) - f(x)}{\varepsilon}.
	\]
	\item اگر تابع در نقطه‌ی $x$ مشتق‌پذیر باشد، داریم:
	\[
	Df(x)\cdot h = \nabla f(x)^T h.
	\]
\end{itemize}

% یادداشت تکمیلی:
% در روش‌های گرادیانی، جهت حرکت معمولاً جهت "بیشترین کاهش" است که همان منفی گرادیان است. این جهت، شیب محلی تابع را بیشترین مقدار منفی می‌کند.:contentReference[oaicite:3]{index=3}

\subsection{روش بیشترین نزول \lr{(Steepest Descent)}}

برای کمینه‌کردن تابع چندمتغیره:

\[
x_{k+1} = x_k - \alpha_k \nabla f(x_k),
\]

که در آن $\alpha_k$ طول قدم است و باید طوری انتخاب شود که مقدار تابع کاهش کافی داشته باشد.

برای انتخاب $\alpha_k$ می‌توان تابع تک‌متغیره‌ی زیر را تعریف کرد:

\[
h(\alpha) = f(x_k - \alpha \nabla f(x_k)),
\]

و سپس نقطه‌ی کمینه‌ی محلی این تابع را یافت (مسأله‌ی بهینه‌سازی تک‌متغیره).

\subsection{الگوریتم‌های مبتنی بر جستجوی خط}

در روش‌های \textbf{جستجوی خط}، در هر تکرار:

\begin{itemize}
	\item یک جهت جستجو $p_k$ انتخاب می‌شود؛
	\item طول قدم $\alpha_k$ در آن جهت تعیین می‌شود:
	\[
	x_{k+1} = x_k + \alpha_k p_k.
	\]
\end{itemize}

معمولاً جهت $p_k$ باید \textbf{جهت نزولی} باشد:

\[
p_k^T \nabla f_k < 0,
\]

تا حرکت روی این جهت باعث کاهش تابع شود.

بسیاری از الگوریتم‌ها جهت را به شکل زیر انتخاب می‌کنند:

\[
p_k = - H_k \nabla f_k,
\]

که $H_k$ ماتریسی (مثلاً تقریب معکوس هسیان) است؛ در این صورت:

\[
p_k^T \nabla f_k = - \nabla f_k^T H_k \nabla f_k.
\]

اگر $H_k$ معین‌مثبت باشد، این کمیت منفی است و جهت نزولی داریم.

\subsection{طول قدم و مسأله‌ی یک‌بعدی}

تابع جستجوی خط:

\[
\phi(\alpha) = f(x_k + \alpha p_k), \quad \alpha > 0.
\]

می‌خواهیم $\alpha_k$ را طوری انتخاب کنیم که $\phi(\alpha)$ به اندازه‌ی کافی کم شود؛ ایده‌های معمول:

\begin{itemize}
	\item پیدا کردن کمینه‌ی محلی یا جهانی $\phi$ (در عمل اغلب ممکن نیست).
	\item اعمال قواعد عملی انتخاب طول قدم مانند:
	\begin{itemize}
		\item کمینه‌سازی (یا کمینه‌سازی محدود روی بازه‌ی $[0,s]$)،
		\item قاعده‌ی آرمیجو،
		\item شروط ولفه،
		\item شروط گلدشتاین،
		\item طول پله‌ی ثابت یا پله‌های کاهشی.
	\end{itemize}
\end{itemize}

\subsection{قاعده‌ی آرمیجو و سایر قواعد طول قدم}

\begin{itemize}
	\item \textbf{قاعده‌ی کمینه‌سازی}:
	\[
	\alpha_k = \arg\min_{\alpha>0} f(x_k + \alpha p_k).
	\]
	\item \textbf{قاعده‌ی کمینه‌سازی محدود}:
	\[
	\alpha_k = \arg\min_{\alpha\in[0,s]} f(x_k + \alpha p_k).
	\]
	\item \textbf{طول پله‌ی ثابت}:
	\[
	\alpha_k = s.
	\]
	\begin{itemize}
		\item اگر $s$ خیلی بزرگ باشد، الگوریتم ممکن است واگرا شود؛
		\item اگر $s$ خیلی کوچک باشد، همگرایی بسیار کند می‌شود.
	\end{itemize}
	\item \textbf{پله‌های کاهشی}: $\alpha_k \to 0$ و $\sum_k \alpha_k = \infty$.
\end{itemize}

% یادداشت تکمیلی:
% قواعد آرمیجو و ولفه تضمین می‌کنند که هم "کاهش کافی" داشته باشیم و هم طول قدم بیش از حد کوچک نشود، و در نتیجه همگرایی روش‌های گرادیانی برای توابع هموار تضمین می‌شود.:contentReference[oaicite:4]{index=4}

\subsection{درونیابی مربعی \lr{(Quadratic Interpolation)}}

ایده: برای پیدا کردن $\alpha$ روی بازه‌ای که می‌دانیم کمینه‌ی محلی در آن قرار دارد، تابع تک‌متغیره‌ی $\phi(\alpha)$ را با یک چندجمله‌ای درجه‌دو تقریب می‌زنیم.

\begin{itemize}
	\item سه نقطه‌ی متوالی $a,b,c$ را طوری انتخاب می‌کنیم که:
	\[
	\phi(b) < \phi(a), \quad \phi(b) < \phi(c).
	\]
	\item با مقادیر تابع در این سه نقطه، یک تابع درجه‌دو برازش می‌کنیم.
	\item کمینه‌ی این تابع درجه‌دو $\bar\alpha$ بین $a$ و $c$ قرار می‌گیرد.
	\item سپس یکی از نقاط را با $\bar\alpha$ جایگزین کرده و فرآیند را تکرار می‌کنیم.
\end{itemize}

\subsection{درونیابی مکعبی \lr{(Cubic Interpolation)}}

در روش درونیابی مکعبی برای جستجوی خط:

\begin{itemize}
	\item ابتدا با یک طول قدم اولیه $s$ شروع می‌کنیم و بازه‌ای $[a,b]$ می‌یابیم که کمینه‌ی محلی در آن قرار دارد.
	\item سپس با استفاده از مقادیر $\phi(a),\phi(b)$ و مشتق‌ها $\phi'(a),\phi'(b)$، یک چندجمله‌ای درجه‌سه برازش می‌کنیم.
	\item کمینه‌ی این چندجمله‌ای $\bar\alpha$ در بازه‌ی $(a,b)$ قرار می‌گیرد.
	\item جایگزینی و تکرار تا رسیدن به شرط توقف (مثلاً طول بازه کوچک شود یا شرط آرمیجو/ولفه برقرار گردد).
\end{itemize}

برای پایدارتر شدن الگوریتم، معمولاً محدودیت‌هایی از نوع زیر اعمال می‌شود:

\[
\bar\alpha \in \left[a + \tfrac{1}{10}(b-a),\, b - \tfrac{1}{10}(b-a)\right].
\]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{جلسه سوم: روش‌های فراابتکاری}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{چرا روش‌های فراابتکاری؟}

\begin{itemize}
	\item بعضی مسائل آن‌قدر پیچیده یا غیرمحدب‌اند که پیدا کردن جواب بهینه‌ی سراسری عملاً ممکن نیست.
	\item \textbf{روش ابتکاری} \lr{(Heuristic)}: روشی است که قادر به یافتن جواب‌های خوب (نه لزوماً بهینه) برای یک مسأله‌ی خاص است.
	\item سنتاً برای هر مسأله لازم بود یک روش ابتکاری مخصوص همان مسأله طراحی شود.
	\item \textbf{روش فراابتکاری} \lr{(Metaheuristic)}: چارچوب و استراتژی کلی‌ای است برای ساختن روش‌های ابتکاری در طیف وسیعی از مسائل.
\end{itemize}

\subsection{مثال: مسأله‌ی با چند کمینه‌ی محلی}

مثال حداقل مربعات غیرخطی:

\[
\min_{x\in\mathbb{R}^p} \quad r_1(x)^2 + r_2(x)^2 + \dots + r_m(x)^2,
\]

که در آن:

\[
r_j(x) = y_j - \varphi(t_j; x).
\]

برای مثال اگر $\varphi(t;x) = x\sin t$ باشد و $y_j$ نمونه‌های نویزی این تابع باشند، تابع هزینه می‌تواند چندین کمینه‌ی محلی داشته باشد.

\begin{itemize}
	\item این مسأله غیرمحدب است و چندین کمینه‌ی محلی دارد.
	\item روش‌های جستجوی محلی مبتنی بر گرادیان (مثل گرادیان‌دسنت، نیوتن و ...) فقط تضمین می‌کنند به یک کمینه‌ی محلی برسند، نه سراسری.
	\item کیفیت جواب شدیداً به نقطه‌ی اولیه بستگی دارد.
	\item یک راه ساده: اجرای چندباره‌ی یک روش محلی از نقاط اولیه‌ی تصادفی.
	\item روش‌های فراابتکاری سعی می‌کنند بین جستجوی محلی و یک استراتژی سطح بالاتر تعادل ایجاد کنند تا بتوان از کمینه‌های محلی فرار کرد و فضای جستجو را بهتر پوشش داد.
\end{itemize}

\subsection{جستجوی محلی برای مسائل گسسته (مثال وزیرها)}

\begin{itemize}
	\item تابع هزینه: تعداد وزیرهایی که همدیگر را می‌بینند.
	\item حرکت: جابه‌جاکردن هر وزیر در ستون خودش به‌گونه‌ای که تابع هزینه کم شود.
	\item این نوع جستجو معمولاً به یک کمینه‌ی محلی می‌رسد که الزماً جواب سراسری نیست.
\end{itemize}

\subsection{الگوریتم بالا رفتن از تپه \lr{(Hill-Climbing)}}

\begin{itemize}
	\item حرکت‌های پی‌درپی در جهت \emph{افزایش تابع هدف} یا \emph{کاهش تابع هزینه}.
	\item الگوریتم وقتی متوقف می‌شود که به یک قله (کمینه‌ی محلی) برسد؛ یعنی هیچ همسایه‌ی بهتری موجود نباشد.
	\item در مسائل گسسته، این قله همان کمینه‌ی محلی نسبت به اعمال حرکت‌های مجاز است.
\end{itemize}

انواع:

\begin{itemize}
	\item \textbf{بالارفتن تصادفی \lr{(Stochastic hill-climbing)}}:
	\begin{itemize}
		\item انتخاب تصادفی بین حرکت‌های بهبوددهنده؛
		\item احتمال انتخاب می‌تواند متناسب با شیب بهبود باشد.
	\end{itemize}
	\item \textbf{اولین انتخاب \lr{(First-choice hill-climbing)}}:
	\begin{itemize}
		\item تولید یک دنباله‌ی تصادفی از جانشین‌ها تا وقتی یک جانشین بهتر پیدا شود.
		\item مناسب وقتی تعداد جانشین‌ها زیاد است.
	\end{itemize}
	\item \textbf{شروع تصادفی \lr{(Random-start hill-climbing)}}:
	\begin{itemize}
		\item اجرای الگوریتم بالا رفتن از تپه از چندین نقطه‌ی اولیه‌ی تصادفی، برای فرار از کمینه‌های محلی.
	\end{itemize}
\end{itemize}

\subsection{جستجوی پرتوی محلی \lr{(Beam Search)}}

\begin{itemize}
	\item به‌جای نگه‌داشتن یک نقطه، $K$ نقطه‌ی همزمان در فضای جستجو نگه می‌داریم.
	\item در شروع: انتخاب $K$ نقطه‌ی تصادفی.
	\item در هر تکرار:
	\begin{itemize}
		\item همسایه‌های هر یک از $K$ نقطه تولید می‌شوند؛
		\item از بین همه‌ی این همسایه‌ها، بهترین $K$ نقطه برای ادامه انتخاب می‌شود.
	\end{itemize}
	\item تفاوت با شروع تصادفی: اطلاعات بین این $K$ مسیر به‌اشتراک گذاشته می‌شود.
	\item \textbf{جستجوی پرتوی تصادفی}:
	\begin{itemize}
		\item انتخاب $K$ جانشین متناسب با کیفیت همسایه‌ها (نه لزوماً بهترین‌ها)؛
		\item مشکل کم‌بودن تنوع در \lr{Beam Search} عادی را کاهش می‌دهد.
	\end{itemize}
\end{itemize}

\subsection{الگوریتم تبرید شبیه‌سازی‌شده \lr{(Simulated Annealing)}}

ایده‌ی اصلی:

\begin{itemize}
	\item اگر همسایه‌ی جدید هزینه‌ی کمتر داشته باشد، آن را \emph{حتماً} می‌پذیریم.
	\item اگر هزینه‌ی بیشتر داشته باشد، آن را با احتمال:
	\[
	\exp\left(-\frac{y_{\text{جدید}} - y_{\text{فعلی}}}{T}\right)
	\]
	می‌پذیریم، که $T$ «دما» است.
\end{itemize}

نکات:

\begin{itemize}
	\item ابتدا $T$ بزرگ است؛ پذیرش حرکات بد (افزاینده‌ی هزینه) زیاد است و الگوریتم تقریباً مانند جستجوی تصادفی عمل می‌کند.
	\item با گذشت زمان، $T$ کاهش می‌یابد؛ احتمال پذیرش حرکات بد کم می‌شود و الگوریتم بیشتر در جهت‌های بهبوددهنده حرکت می‌کند.
	\item این باعث می‌شود الگوریتم بتواند از کمینه‌های محلی عبور کند.
\end{itemize}

\paragraph{طراحی عملی SA}

\begin{itemize}
	\item \textbf{زمان‌بندی دما}:
	\begin{itemize}
		\item دما با چه نرخ و بر چه قاعده‌ای کاهش یابد؟ (مثلاً $T_{k+1} = \alpha T_k$ با $\alpha<1$).
		\item در هر سطح دما چند تکرار انجام شود؟
	\end{itemize}
	\item \textbf{ساختار همسایگی}: تعریف این‌که چه حرکت‌هایی روی جواب مجازند.
	\item \textbf{نقطه‌ی اولیه}: تصادفی یا ساختاریافته.
\end{itemize}

\subsection{الگوریتم ژنتیک \lr{(Genetic Algorithm)}}

\begin{itemize}
	\item شروع با یک \textbf{جمعیت اولیه} از جواب‌های قابل قبول.
	\item در هر نسل:
	\begin{itemize}
		\item \textbf{انتخاب} \lr{(Selection)}: برخی از اعضای جمعیت به‌عنوان والد (بر اساس تابع سازگاری) انتخاب می‌شوند.
		\item \textbf{تلاقی} \lr{(Crossover)}: والدها به‌صورت تصادفی جفت می‌شوند و فرزندان تولید می‌کنند؛ ژن‌های فرزندان ترکیبی از ژن‌های والدین هستند.
		\item \textbf{جهش} \lr{(Mutation)}: با احتمال کم، بعضی ژن‌ها به‌طور تصادفی تغییر می‌کنند.
		\item \textbf{نخبه‌گرایی} \lr{(Elitism)}: تعدادی از بهترین افراد نسل فعلی مستقیماً به نسل بعد منتقل می‌شوند.
	\end{itemize}
	\item شرط توقف: تعداد نسل‌ها، محدودیت زمانی، یا عدم بهبود معنادار تابع هزینه در چند نسل متوالی.
\end{itemize}

پارامترهای کلیدی:

\begin{itemize}
	\item اندازه‌ی جمعیت \lr{(Population size)}.
	\item نرخ جهش \lr{(Mutation rate)}.
	\item نوع تلاقی (یک‌نقطه‌ای، دو‌نقطه‌ای، یکنواخت، و غیره).
	\item تابع سازگاری \lr{(Fitness function)}، که معمولاً منفی تابع هزینه یا تابع هدف نرمال‌شده است.
\end{itemize}

\subsection{مثال‌های پیوسته و گسسته در \lr{GA}}

\paragraph{مسأله‌ی گسسته (مثال وزیرها)}

نمایش یک چینش به‌صورت کد باینری یا عددی، محاسبه‌ی تعداد وزیرهایی که یکدیگر را تهدید می‌کنند، استفاده از انتخاب، تلاقی و جهش برای رسیدن به چینش‌هایی با هزینه‌ی کمتر.

\paragraph{مسأله‌ی پیوسته}

\begin{itemize}
	\item \textbf{تلاقی}: برای دو والد $p_1$ و $p_2$، یک عدد تصادفی $r\in[0,1]$ انتخاب کرده و فرزند:
	\[
	c_1 = p_1 + r(p_2 - p_1)
	\]
	را می‌سازیم.
	\item \textbf{جهش}: یک بعد $i$ را انتخاب کرده و:
	\[
	x[i] \leftarrow x[i] + \eta,\quad \eta \sim \mathcal{N}(0,\sigma^2).
	\]
\end{itemize}

\subsection{تابع راستریگین \lr{(Rastrigin)}}

فرم تابع $p$-بعدی راستریگین:

\[
f(x) = 10p + \sum_{i=1}^p \left(x_i^2 - 10\cos(2\pi x_i)\right).
\]

\begin{itemize}
	\item این تابع دارای تعداد زیادی کمینه‌ی محلی است؛
	\item برای آزمون عملکرد الگوریتم‌های فراابتکاری (مثل \lr{GA} و \lr{SA}) بسیار استفاده می‌شود.
\end{itemize}

\section{جلسه چهارم: پایه‌های بهینه‌سازی نامقید}


در این جلسه روی مسأله‌ی نامقید تمرکز می‌کنیم:

\[
\min_{x\in\mathbb{R}^n} f(x),
\]

که در آن $f:\mathbb{R}^n\to\mathbb{R}$ تابعی هموار است.

\subsection{بسط تیلور در حالت چندمتغیره}

فرض کنید $f$ در همسایگی $x$ دوبار مشتق‌پذیر باشد. برای هر جهت $p\in\mathbb{R}^n$، بسط تیلور درجه‌ی اول:

\[
f(x+p) = f(x) + \nabla f(x)^T p + o(\|p\|).
\]

اگر مشتق دوم پیوسته باشد، می‌توان نوشت:

\[
f(x+p) = f(x) + \nabla f(x)^T p + \frac{1}{2} p^T \nabla^2 f(x + t p) p,\qquad t\in(0,1).
\]

و در صورت تقریب هسیان در نقطه‌ی $x$:

\[
f(x+p) \approx f(x) + \nabla f(x)^T p + \frac{1}{2} p^T \nabla^2 f(x) p.
\]

\textbf{فرم انتگرالی} بسط تیلور (که در اسلایدها آمده بود):

\[
\begin{aligned}
	\nabla f(x+p) &= \nabla f(x) + \int_0^1 \nabla^2 f(x+tp)\,p\,dt,\\
	f(x+p) &= f(x) + \nabla f(x)^T p + \int_0^1 (1-t)\,p^T \nabla^2 f(x+tp) p\,dt.
\end{aligned}
\]

این روابط اساس تحلیل شرایط لازم و کافی بهینگی هستند.

\subsection{شرایط لازم مرتبه‌ی اول برای کمینه‌ی محلی}

\textbf{تعریف (کمینه‌ی محلی).} نقطه‌ی $x^\star$ را کمینه‌ی محلی تابع $f$ می‌گوییم اگر:

\[
\exists r>0:\quad \forall x\in B_r(x^\star)\quad f(x^\star)\le f(x).
\]

\textbf{قضیه.} اگر $f$ در همسایگی $x^\star$ مشتق‌پذیر باشد و $x^\star$ کمینه‌ی محلی باشد، آنگاه:

\[
\nabla f(x^\star) = 0.
\]

\textbf{اثبات (اسکچ).} اگر $\nabla f(x^\star)\ne 0$، جهت $p=-\nabla f(x^\star)$ را در نظر بگیرید و تابع یک‌بعدی
$\varphi(\alpha)=f(x^\star+\alpha p)$ را بررسی کنید. مشتق $\varphi'(0)=\nabla f(x^\star)^T p = -\|\nabla f(x^\star)\|^2<0$، بنابراین در همسایگی صفر، مقادیری از $\alpha>0$ داریم که $\varphi(\alpha)<\varphi(0)$؛ یعنی مقدار تابع کاهش می‌یابد که با کمینه‌بودن $x^\star$ در تناقض است.

\subsection{شرایط مرتبه‌ی دوم}

اگر علاوه بر مشتق اول، مشتق دوم نیز وجود داشته باشد، از بسط تیلور درجه‌ی دوم استفاده می‌کنیم:

\[
f(x^\star + p) = f(x^\star) + \nabla f(x^\star)^T p + \frac{1}{2} p^T \nabla^2 f(x^\star) p + o(\|p\|^2).
\]

\begin{itemize}
	\item اگر $x^\star$ کمینه‌ی محلی و $\nabla f(x^\star)=0$، آنگاه برای $p$های کوچک:
	\[
	f(x^\star + p) - f(x^\star) \approx \frac{1}{2} p^T \nabla^2 f(x^\star) p \ge 0.
	\]
	پس \textbf{هسیان در $x^\star$ باید نیمه معین‌مثبت باشد} (شرط لازم).
	\item اگر $\nabla f(x^\star)=0$ و $\nabla^2 f(x^\star)\succ 0$ (معین‌مثبت)، آن‌گاه $x^\star$ یک \textbf{کمینه‌ی محلی یکتا} است (شرط کافی).
\end{itemize}

\subsection{شکل هندسی شرایط مرتبه‌ی دوم}

\begin{itemize}
	\item اگر همه‌ی مقادیر ویژه‌ی هسیان مثبت باشند، تابع در همسایگی شبیه کاسه‌ای رو به بالا است.
	\item اگر بعضی مقادیر ویژه مثبت و بعضی منفی باشند، نقطه‌ی $\nabla f=0$ یک \textbf{نقطهٔ زینی} است.
	\item اگر همه مقادیر ویژه منفی باشند، نقطه‌ی ایستا بیشینه‌ی محلی است.
\end{itemize}

\subsection{توابع محدب و بهینگی}

اگر $f$ روی مجموعه‌ی محدب $S$، \textbf{محدب و مشتق‌پذیر} باشد:

\[
f(y) \ge f(x) + \nabla f(x)^T (y-x),\qquad \forall x,y\in S.
\]

\textbf{قضیه.} اگر $f$ محدب و مشتق‌پذیر باشد، آنگاه هر نقطه‌ی $x^\star$ که $\nabla f(x^\star)=0$ داشته باشد، \textbf{کمینه‌ی سراسری} است.

\textbf{نتیجه‌ی مهم:} در مسائل نامقید محدب، پیدا کردن یک نقطه‌ی ایستا کافی است تا جواب سراسری بهینه را به‌دست آوریم. این یکی از دلایل اهمیت بهینه‌سازی محدب است.

\subsection{قوت محدبیت و یکتایی جواب}

\textbf{تعریف (محدبیت قوی).} تابع $f$ را \textbf{$\mu$-محدب قوی} می‌نامیم اگر:

\[
f(y) \ge f(x) + \nabla f(x)^T (y-x) + \frac{\mu}{2}\|y-x\|^2,\qquad \forall x,y.
\]

در این صورت:
\begin{itemize}
	\item $f$ حداکثر یک کمینه‌ی سراسری دارد؛
	\item هسیان در هر نقطه‌ای که وجود دارد، $\nabla^2 f(x)\succeq \mu I$.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{جلسه پنجم: روش‌های جستجوی خط}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

در روش‌های جستجوی خط، در هر گام $k$:

\[
x_{k+1} = x_k + \alpha_k p_k,
\]

که $p_k$ یک جهت نزولی و $\alpha_k>0$ طول قدم است.

\subsection{روش‌های دقیق و نادقیق}

\begin{itemize}
	\item \textbf{جستجوی خط دقیق:}
	\[
	\alpha_k = \arg\min_{\alpha>0} f(x_k + \alpha p_k).
	\]
	معمولاً هزینه‌بر است یا اصلاً عملی نیست.
	\item \textbf{جستجوی خط نادقیق:} به‌جای پیدا کردن کمینه‌ی دقیق، $\alpha_k$ را طوری انتخاب می‌کنیم که شرایطی از نوع «کاهش کافی» و «انحنا» را ارضا کند.
\end{itemize}

\subsection{شرط آرمیجو (کاهش کافی)}

شرط آرمیجو می‌گوید طول قدم $\alpha$ قابل قبول است اگر:

\[
f(x_k + \alpha p_k) \le f(x_k) + c_1 \alpha \nabla f(x_k)^T p_k,
\]

که در آن $c_1\in(0,1)$ معمولاً عدد کوچکی مثل $10^{-4}$ است.

این شرط تضمین می‌کند که کاهش تابع $f$ حداقل به‌اندازه‌ی یک سهم ثابت از کاهش پیش‌بینی‌شده توسط تقریب خطی باشد.

\subsection{شرط انحنا و شروط ولفه}

برای تضمین این‌که طول قدم خیلی کوچک نشود، از \textbf{شرط انحنا} استفاده می‌شود. دو نوع معروف:

\begin{itemize}
	\item \textbf{شرط ولفه:}
	\[
	\nabla f(x_k + \alpha p_k)^T p_k \ge c_2 \nabla f(x_k)^T p_k,
	\]
	که $c_2\in(c_1,1)$ (مثلاً $c_2=0.9$).
	\item \textbf{شرط ولفه‌ی قوی:}
	\[
	|\nabla f(x_k + \alpha p_k)^T p_k| \le c_2 |\nabla f(x_k)^T p_k|.
	\]
\end{itemize}

\textbf{شروط ولفه} (یا ولفه‌ی قوی) معمولاً همراه با شرط آرمیجو استفاده می‌شوند تا هم کاهش کافی و هم طول قدم مناسب تضمین شود.

\subsection{شرط گلدشتاین}

شرط گلدشتاین بازه‌ای برای مقدار تابع تعریف می‌کند:

\[
f(x_k) + (1-c)\alpha \nabla f(x_k)^T p_k \le f(x_k + \alpha p_k) 
\le f(x_k) + c\alpha \nabla f(x_k)^T p_k,
\]

که $c\in(0,1/2)$ است.

بازه‌ی گلدشتاین به‌نوعی تعادل بین کاهش کافی و عدم «افراط» در کاهش را فراهم می‌کند.

\subsection{تعریف نرخ‌های همگرایی}

برای دنباله‌ی $\{x_k\}$ که به $x^\star$ همگرا می‌شود، خطای $e_k=\|x_k-x^\star\|$ را در نظر بگیرید.

\begin{itemize}
	\item \textbf{همگرایی Q-خطی:}
	\[
	\exists r\in(0,1):\quad e_{k+1} \le r e_k\quad \text{برای $k$های بزرگ}.
	\]
	\item \textbf{همگرایی Q-فراخطی \lr{(Superlinear)}:}
	\[
	\lim_{k\to\infty} \frac{e_{k+1}}{e_k} = 0.
	\]
	\item \textbf{همگرایی Q-درجه‌دو \lr{(Quadratic)}:}
	\[
	e_{k+1} \le C e_k^2,\quad C>0.
	\]
\end{itemize}

این تعاریف در تحلیل روش‌های نیوتن و شبه‌نیوتن بسیار مهم‌اند.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{جلسه ششم: روش‌های عملی جستجوی خط}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

در عمل، باید الگوریتمی داشته باشیم که فقط با ارزیابی تابع و گاهی گرادیان، $\alpha_k$ را پیدا کند.

\subsection{جستجوی خط پسگرد \lr{(Backtracking)} با آرمیجو}

الگوریتم ساده:

\begin{itemize}
	\item پارامترها: $0<\beta<1$ (مثلاً $0.5$)، $0<c_1<1$ (مثلاً $10^{-4}$).
	\item مقدار اولیه: $\alpha\gets \alpha_0$ (مثلاً $\alpha_0=1$).
	\item تا وقتی
	\[
	f(x_k + \alpha p_k) > f(x_k) + c_1 \alpha \nabla f(x_k)^T p_k
	\]
	داریم، $\alpha\gets \beta\alpha$.
	\item در نهایت $\alpha_k = \alpha$ پذیرفته می‌شود.
\end{itemize}

\textbf{مزایا:} پیاده‌سازی بسیار ساده، فقط از تابع و گرادیان در نقطه‌ی شروع استفاده می‌کند، و برای روش‌های گرادیان و نیوتن/شبه‌نیوتن کارا است.

\subsection{جستجوی خط با شروط ولفه (الگوریتم \lr{Bracketing \& Zoom})}

الگوریتم‌های استاندارد (مثل الگوریتم \lr{Nocedal-Wright}):

\begin{enumerate}
	\item از یک $\alpha_{\max}$ شروع کرده و $\alpha$ را به‌تدریج بزرگ می‌کنیم تا بازه‌ای $[0,\bar\alpha]$ پیدا شود که در آن یا شرط کاهش کافی نقض شود، یا شرط انحنا نقض شود؛ به این کار \textbf{bracketing} می‌گویند.
	\item سپس در بازه‌ی محدود‌شده، با استفاده از \textbf{درونیابی درجه‌دو یا درجه‌سه}، مقدار جدیدی از $\alpha$ پیشنهاد می‌شود (تابع \texttt{zoom} در بسیاری از پیاده‌سازی‌ها).
	\item این فرآیند تا زمانی ادامه می‌یابد که هر دو شرط آرمیجو و ولفه (یا ولفه‌ی قوی) برقرار شوند.
\end{enumerate}

\subsection{درونیابی مربعی و مکعبی در جستجوی خط}

برای تقریب $\phi(\alpha)=f(x_k+\alpha p_k)$:

\begin{itemize}
	\item درونیابی \textbf{مربعی}: با استفاده از سه نقطه $(\alpha_i,\phi(\alpha_i))$ یک چندجمله‌ای درجه‌دو ساخته و کمینه‌ی آن را به‌عنوان $\bar\alpha$ پیشنهاد می‌کنیم.
	\item درونیابی \textbf{مکعبی}: با استفاده از دو نقطه و مشتق آن‌ها (چهار شرط)، یک چندجمله‌ای درجه‌سه ساخته و کمینه‌ی آن را پیشنهاد می‌کنیم.
\end{itemize}

برای جلوگیری از انتخاب $\bar\alpha$ خیلی نزدیک به لبه‌های بازه، معمولاً محدود می‌کنیم:

\[
\bar\alpha \in [\alpha_{\min} + \theta(\alpha_{\max}-\alpha_{\min}),\; \alpha_{\max}-\theta(\alpha_{\max}-\alpha_{\min})]
\]

با $\theta$ کوچک (مثلاً $0.1$).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{جلسه هفتم: روش‌های نیوتن و نیوتنِ تصحیح‌شده}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{روش نیوتن نامقید}

مدل درجه‌دوم تابع در نقطه‌ی $x_k$:

\[
m_k(p) = f(x_k) + \nabla f(x_k)^T p + \frac{1}{2} p^T \nabla^2 f(x_k) p.
\]

اگر $\nabla^2 f(x_k)$ معین‌مثبت و معکوس‌پذیر باشد، کمینه‌ی این مدل از حل دستگاه:

\[
\nabla^2 f(x_k) p_k = -\nabla f(x_k)
\]

به‌دست می‌آید؛ یعنی:

\[
p_k = -\nabla^2 f(x_k)^{-1} \nabla f(x_k).
\]

و سپس:

\[
x_{k+1} = x_k + p_k
\]

(در نسخه‌ی کلاسیک نیوتن، طول قدم برابر ۱ است؛ در عمل اغلب با جستجوی خط ترکیب می‌شود.)

\subsection{نرخ همگرایی روش نیوتن}

فرض کنید:

\begin{itemize}
	\item $x^\star$ کمینه‌ی محلی با $\nabla f(x^\star)=0$ است؛
	\item هسیان در $x^\star$ معین‌مثبت و معکوس‌پذیر است؛
	\item $\nabla^2 f$ در همسایگی $x^\star$ پیوسته است.
\end{itemize}

آنگاه اگر $x_0$ به‌اندازه‌ی کافی به $x^\star$ نزدیک باشد، دنباله‌ی تولیدشده توسط روش نیوتن با طول قدم ۱:

\[
x_{k+1}=x_k-\nabla^2 f(x_k)^{-1}\nabla f(x_k),
\]

\textbf{با نرخ درجه‌دو} به $x^\star$ همگرا می‌شود:

\[
\|x_{k+1}-x^\star\|\le C\|x_k-x^\star\|^2.
\]

\subsection{مشکلات روش نیوتن}

\begin{itemize}
	\item اگر هسیان $\nabla^2 f(x_k)$ \textbf{منفرد} یا \textbf{نامعین‌مثبت} باشد، ممکن است:
	\begin{itemize}
		\item دستگاه نیوتن قابل حل نباشد؛
		\item جهت $p_k$ جهت نزولی نباشد.
	\end{itemize}
	\item حتی اگر هسیان معین‌مثبت باشد، بدون جستجوی خط ممکن است دور از جواب رفتاری ناپایدار داشته باشیم.
\end{itemize}

\subsection{روش نیوتنِ تعدیل‌شده \lr{(Modified Newton)}}

ایده: به‌جای استفاده‌ی مستقیم از هسیان، ماتریسی معین‌مثبت $B_k$ بسازیم که تقریب خوبی از $\nabla^2 f(x_k)$ باشد:

\[
B_k p_k = -\nabla f(x_k),\qquad B_k\succ 0.
\]

چند استراتژی:

\begin{itemize}
	\item \textbf{افزودن مضربی از ماتریس واحد:}
	\[
	B_k = \nabla^2 f(x_k) + \lambda_k I,\quad \lambda_k\ge 0,
	\]
	به‌طوری که $B_k$ معین‌مثبت شود.
	\item \textbf{تصحیح مقادیر ویژه:} تجزیه‌ی طیفی $\nabla^2 f(x_k)=Q\Lambda Q^T$؛ سپس:
	\[
	\tilde\Lambda_{ii} = \max(\Lambda_{ii},\epsilon),
	\]
	و $B_k=Q\tilde\Lambda Q^T$.
\end{itemize}

این کار تضمین می‌کند جهت $p_k$ جهت نزولی باشد:

\[
p_k^T \nabla f(x_k) = -\nabla f(x_k)^T B_k^{-1} \nabla f(x_k) < 0.
\]

\subsection{نمود هندسی روش نیوتن}

می‌توان نشان داد با تغییر دستگاه مختصات به دستگاهی که محورهای آن روی بردارهای ویژه‌ی هسیان قرار می‌گیرند، گام نیوتن در هر جهت متناسب با $\frac{1}{\lambda_i}$ (مقدار ویژه‌ی متناظر) مقیاس می‌شود؛ در جهت‌هایی که انحنای تابع زیاد است (مقادیر ویژه‌ی بزرگ)، گام کوچک‌تر و در جهت‌هایی که انحنا کم است، گام بزرگ‌تر است. این رفتار دلیل سرعت همگرایی زیاد روش نیوتن در اطراف جواب است.


\section{جلسه هشتم: جستجوی خط (ادامه) و همگرایی}


در این جلسه روی ترکیب روش‌های نیوتن/شبه‌نیوتن با جستجوی خط و تحلیل همگرایی تمرکز می‌شود.

\subsection{روش نیوتن دمپ‌شده \lr{(Damped Newton)}}

در عمل، برای \lr{global convergence}، نیوتن را با جستجوی خط ترکیب می‌کنیم:

\[
\begin{aligned}
	\nabla^2 f(x_k)p_k &= -\nabla f(x_k),\\
	x_{k+1} &= x_k + \alpha_k p_k,
\end{aligned}
\]

که $\alpha_k$ با یک الگوریتم جستجوی خط (مثلاً آرمیجو-ولفه) انتخاب می‌شود.

\textbf{نتیجه:} در زیر فرضیات استاندارد (هسیان لیپشیتز، تابع محدود از پایین، جهت‌های نزولی و شروط ولفه)، روش نیوتن دمپ‌شده:

\begin{itemize}
	\item به یک نقطه‌ی ایستا همگرا می‌شود (همگرایی سراسری)؛
	\item و وقتی به‌اندازه‌ی کافی نزدیک جواب شد، $\alpha_k\to1$ و همگرایی \textbf{درجه‌دو} می‌شود.
\end{itemize}

\subsection{نرخ‌های همگرایی در عمل}

\begin{itemize}
	\item روش‌های گرادیانی با گام‌های مناسب برای توابع $\mu$-محدب قوی با گرادیان لیپشیتز، معمولاً \textbf{Q-خطی} همگرا می‌شوند.
	\item روش نیوتن دمپ‌شده، محلی \textbf{درجه‌دو} است.
	\item روش‌های شبه‌نیوتن خوب (مثلاً \lr{BFGS}) غالباً \textbf{فراخطی} \lr{(superlinear)} همگرا می‌شوند.
\end{itemize}

\subsection{شهود زوتندیک \lr{(Zoutendijk)} برای همگرایی}

برای بسیاری از روش‌های جستجوی خط که:

\begin{itemize}
	\item جهت‌های نزولی تولید می‌کنند؛
	\item و طول قدم‌ها شروط ولفه را ارضا می‌کنند،
\end{itemize}

قضیه‌ی زوتندیک می‌گوید:

\[
\sum_{k=0}^\infty \cos^2\theta_k \,\|\nabla f(x_k)\|^2 < \infty,
\]

که در آن $\theta_k$ زاویه بین جهت $p_k$ و $-\nabla f(x_k)$ است. از این قضیه نتیجه می‌شود که:

\[
\liminf_{k\to\infty} \|\nabla f(x_k)\| = 0,
\]

و تحت فرضیات مناسب‌تر، حتی $\|\nabla f(x_k)\|\to0$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{جلسه نهم و دهم: روش‌های شبه‌نیوتن}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

ایده: به‌جای محاسبه‌ی هسیان واقعی (که پرهزینه یا نامطمئن است)، در هر گام یک تقریب $B_k$ (یا معکوس آن $H_k$) از هسیان را به‌صورت بازگشتی به‌روز کنیم.

\subsection{شرط سکنت \lr{(Secant Condition)}}

در روش نیوتن داریم:

\[
\nabla^2 f(x_k) s_k = y_k,
\]

که در آن:

\[
s_k = x_{k+1}-x_k,\qquad y_k = \nabla f(x_{k+1}) - \nabla f(x_k).
\]

در شبه‌نیوتن می‌خواهیم ماتریس $B_{k+1}$ چنین شرطی را تقریباً ارضا کند:

\[
B_{k+1} s_k = y_k
\]

(شرط سکنت)، و در عین حال تا حد امکان به $B_k$ نزدیک باشد و معین‌مثبت بماند.

\subsection{فرمول کلی به‌روزرسانی رتبه-۲}

خیلی از روش‌های شبه‌نیوتن، به‌روزرسانی‌هایی از نوع رتبه-۲ دارند:

\[
B_{k+1} = B_k + U_k,
\]

که $U_k$ ماتریسی با رتبه‌ی حداکثر ۲ است و طوری انتخاب می‌شود که:

\begin{itemize}
	\item $B_{k+1}$ متقارن باشد؛
	\item $B_{k+1} s_k = y_k$؛
	\item $B_{k+1}$ تا حد امکان به $B_k$ نزدیک باشد (مثلاً کمینه‌کردن فاصله به‌ازای یک نُرم ماتریسی).
\end{itemize}

\subsection{روش \lr{DFP}}

در فرم \textbf{معکوس هسیان} (یعنی به‌روزرسانی مستقیم $H_k\approx \nabla^2 f(x_k)^{-1}$)، فرمول \lr{DFP}:

\[
H_{k+1}^{\text{DFP}} = H_k 
+ \frac{s_k s_k^T}{s_k^T y_k}
- \frac{H_k y_k y_k^T H_k}{y_k^T H_k y_k}.
\]

اگر $H_0$ معین‌مثبت باشد و $s_k^T y_k >0$، در نتیجه $H_{k+1}$ نیز معین‌مثبت می‌ماند.

\subsection{روش \lr{BFGS} (نسخهٔ مستقیم)}

در فرم مستقیم (تقریب هسیان)، فرمول \lr{BFGS}:

\[
B_{k+1}^{\text{BFGS}} 
= B_k 
- \frac{B_k s_k s_k^T B_k}{s_k^T B_k s_k}
+ \frac{y_k y_k^T}{y_k^T s_k}.
\]

\textbf{خواص مهم:}

\begin{itemize}
	\item متقارن است.
	\item اگر $B_k\succ0$ و $s_k^T y_k >0$، آنگاه $B_{k+1}\succ0$.
	\item به‌صورت ضمنی یک تقریب «بهینه» نسبت به $B_k$ در نُرم مناسب است.
\end{itemize}

\subsection{روش \lr{BFGS} (نسخهٔ معکوس)}

در عمل، برای ساختن جهت جستجو به $H_k\approx B_k^{-1}$ نیاز داریم:

\[
p_k = -H_k \nabla f(x_k).
\]

فرمول به‌روزرسانی $H_k$ در \lr{BFGS}:

\[
\begin{aligned}
	\rho_k &= \frac{1}{y_k^T s_k},\\
	H_{k+1} &= (I - \rho_k s_k y_k^T) H_k (I - \rho_k y_k s_k^T) + \rho_k s_k s_k^T.
\end{aligned}
\]

این فرمول هم معین‌مثبت‌بودن را حفظ می‌کند (اگر $s_k^T y_k>0$) و تنها شامل ضرب ماتریس‌بردار است (نه وارون‌گیری ماتریس).

\subsection{شرط $s_k^T y_k >0$ و نقش جستجوی خط}

برای حفظ معین‌مثبت‌بودن، لازم است $s_k^T y_k>0$.  
در روش‌های عملی، این شرط با استفاده از جستجوی خطی که شروط ولفه‌ی قوی را ارضا کند تقریباً تضمین می‌شود؛ یعنی در انتخاب $\alpha_k$ دقت می‌کنیم که:

\[
y_k^T s_k = (\nabla f(x_{k+1}) - \nabla f(x_k))^T (x_{k+1}-x_k) >0.
\]

\subsection{روش \lr{SR1} (به‌روزرسانی رتبه-۱)}

یک خانواده‌ی دیگر از شبه‌نیوتن‌ها به‌روزرسانی‌های رتبه-۱ هستند؛ معروف‌ترین آن‌ها \lr{SR1} است:

\[
B_{k+1}^{\text{SR1}} = B_k + \frac{(y_k - B_k s_k)(y_k - B_k s_k)^T}{(y_k - B_k s_k)^T s_k}.
\]

این فرم برخلاف \lr{BFGS} لزوماً معین‌مثبت را حفظ نمی‌کند، ولی در برخی مسائل عملی عملکرد بسیار خوبی دارد، چون اطلاعات انحنا را به‌صورت موضعی دقیق‌تر منتقل می‌کند.

\subsection{روش‌های شبه‌نیوتن در عمل}

الگوریتم کلی:

\begin{enumerate}
	\item انتخاب $x_0$ و $H_0$ (مثلاً $H_0=I$).
	\item برای $k=0,1,2,\dots$ تا رسیدن به شرط توقف:
	\begin{enumerate}[label*=\arabic*.]
		\item جهت جستجو:
		\[
		p_k = -H_k \nabla f(x_k).
		\]
		\item پیدا کردن $\alpha_k$ با جستجوی خط (آرمیجو-ولفه).
		\item به‌روزرسانی:
		\[
		x_{k+1} = x_k + \alpha_k p_k.
		\]
		\item محاسبه‌ی:
		\[
		s_k = x_{k+1}-x_k,\qquad y_k = \nabla f(x_{k+1}) - \nabla f(x_k).
		\]
		\item به‌روزرسانی $H_{k+1}$ (یا $B_{k+1}$) با یکی از فرمول‌های شبه‌نیوتن (\lr{BFGS}، \lr{DFP}، \lr{SR1} و ...)، در صورتی که شرط $s_k^T y_k>0$ مناسب برقرار باشد.
	\end{enumerate}
\end{enumerate}

\subsection{همگرایی شبه‌نیوتن}

\begin{itemize}
	\item اگر $f$ دو بار مشتق‌پذیر باشد، هسیان در جواب معین‌مثبت و لیپشیتز باشد، و جستجوی خط شروط ولفه را برآورده کند، آنگاه روش \lr{BFGS} (با $H_0$ مناسب) معمولاً \textbf{فراخطی} به جواب همگرا می‌شود.
	\item برای توابع درجه‌دوم (کواندراتیک) و جستجوی خط دقیق، \lr{BFGS} در نهایت جواب را در حداکثر $n$ گام پیدا می‌کند و رفتار آن با روش گرادیان مزدوج کلاسیک رابطه‌ی نزدیکی دارد.
\end{itemize}

\subsection{نسخه‌های حافظه‌کم \lr{(L-BFGS)}}

در مسائل با ابعاد بسیار بزرگ (مثلاً هزاران یا میلیون‌ها متغیر)، نگهداری ماتریس کامل $H_k$ یا $B_k$ امکان‌پذیر نیست.  
در \textbf{L-BFGS} فقط چند جفت اخیر $(s_k,y_k)$ ذخیره می‌شود و ضرب $H_k\nabla f(x_k)$ به‌صورت بازگشتی و بدون تشکیل ماتریس کامل انجام می‌گیرد. این روش در کاربردهایی مانند یادگیری ماشین و مسائل بزرگ‌مقیاس بسیار پرکاربرد است.
	
\end{document}
